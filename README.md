# SpeakingBuddy â€” Luxembourgish Pronunciation Trainer

A web app that helps users learn and practice Luxembourgish pronunciation. Users see a word, listen to a native reference recording, record their own attempt, and receive an instant pronunciation score with detailed feedback â€” powered by Praat acoustic analysis.

---

## Table of Contents

1. [Quick Start](#quick-start)
2. [Data Files: CSV & Audio](#data-files-csv--audio)
3. [Adding New Words & Categories](#adding-new-words--categories)
4. [Project Structure](#project-structure)
5. [How It All Connects](#how-it-all-connects-mvp-architecture)
6. [Project Outline Mapping](#project-outline-mapping)
7. [MVP Presentation Talking Points](#mvp-presentation-talking-points)
8. [Commit History](#commit-history)

---

## Quick Start

### Prerequisites

| Tool | Version | Check | Install |
|------|---------|-------|---------|
| Python | 3.10+ | `python --version` | [python.org](https://python.org) or `pyenv install 3.10` |
| pip | any | `pip --version` | Bundled with Python |
| ffmpeg | any | `ffmpeg -version` | `choco install ffmpeg` (Windows) / `brew install ffmpeg` (Mac) |
| Git | any | `git --version` | [git-scm.com](https://git-scm.com) |

> **Windows note:** Use Git Bash or PowerShell. If using Git Bash, always use forward slashes: `.venv/Scripts/activate`, not backslashes.

### 1. Clone & switch branch

```bash
git clone https://github.com/LLOKAI/speakingbuddy.git
cd speakingbuddy
git checkout backend-impl
```

### 2. Set up the backend

```bash
cd backend
python -m venv .venv

# Activate the virtual environment:
source .venv/Scripts/activate    # Windows Git Bash
source .venv/bin/activate        # macOS / Linux
# .venv\Scripts\activate         # Windows CMD

# Install dependencies:
pip install -r requirements.txt
```

### 3. Initialize the database

```bash
# From the backend/ directory, with venv active:
python -m scripts.import_csv --csv data/words.csv --audio-dir reference_audio --clean
python -m scripts.precompute_features
```

This imports 38 Luxembourgish words across 8 categories from the CSV and pre-computes Praat acoustic features for all 38 reference audio files.

> **One-command alternative:** `python -m scripts.pipeline` runs the full chain: validate â†’ preprocess audio â†’ import CSV â†’ extract features.

### 4. Run the app

```bash
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000
```

Open **http://localhost:8000** in your browser. The backend serves both the API and the frontend â€” no Live Server or separate web server needed.

> **Port already in use?** Find what's using it: `netstat -ano | grep :8000` â†’ kill it: `taskkill /F /PID <pid>` (Windows) or `kill <pid>` (Mac/Linux).

### 5. Verify it works

1. Landing page loads with 8 category cards (Animals, Greetings, Food, etc.)
2. Click a category â†’ flashcard page shows the Luxembourgish word + translation
3. Click **ğŸ”Š Listen** â†’ hear the native reference pronunciation
4. Click **ğŸ™ï¸** to record â†’ click again to stop â†’ **â–¶ï¸** plays back your recording
5. Click **ğŸ“Š Evaluate Pronunciation** â†’ score (0-100), five breakdown bars, and improvement tips appear

---

## Data Files: CSV & Audio

### Where files live

```
backend/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ words.csv              â† The source of truth for all words
â”‚   â””â”€â”€ speakingbuddy.db       â† Generated SQLite DB (don't edit directly)
â””â”€â”€ reference_audio/           â† One WAV per word (native speaker recordings)
    â”œâ”€â”€ addi2.wav
    â”œâ”€â”€ bam1.wav
    â”œâ”€â”€ hond1.wav
    â””â”€â”€ ... (38 files total)
```

### CSV format (`backend/data/words.csv`)

The CSV is the **single source of truth**. The database is always regenerated from it.

| Column | Required | Example | Description |
|--------|----------|---------|-------------|
| `LOD Word reference` | Yes | `HOND1` | Unique ID from the LOD dictionary |
| `Audio Reference` | Yes | `hond1` | Filename without `.wav` (script appends it automatically) |
| `Word Category` | Yes | `Animals` | Display name; auto-slugified for URLs (`Animals` â†’ `animals`) |
| `Luxembourgish` | Yes | `Hond` | The word in Luxembourgish |
| `English` | Optional | `dog` | English translation |
| `French` | Optional | `chien` | French translation |
| `German` | Optional | `Hund` | German translation |

Example row:
```csv
HOND1,hond1,Animals,Hond,dog,chien,Hund
```

### Audio file requirements

Each word in the CSV needs a matching WAV file in `backend/reference_audio/`.

| Property | Required value | Why |
|----------|---------------|-----|
| Format | WAV | Praat requires uncompressed audio |
| Sample rate | 22050 Hz | Standardized for consistent feature extraction |
| Channels | Mono (1) | Stereo confuses formant analysis |
| Loudness | â‰ˆ -20 dBFS | Normalized for fair intensity comparison |
| Content | Single word, clear | Silence-trimmed, no background noise |

> **Audio not standardized?** Run `python -m scripts.prepare_audio --audio-dir reference_audio --backup` to auto-convert any input WAV to the correct specs. Originals are saved to `reference_audio/originals/`.

### How CSV â†’ Database works

```
words.csv                          speakingbuddy.db
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LOD Word reference   â”‚           â”‚ categories table        â”‚
â”‚ Audio Reference      â”‚â”€â”€importâ”€â”€â–¶â”‚   id, name, display_nameâ”‚
â”‚ Word Category        â”‚   script  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Luxembourgish        â”‚           â”‚ words table             â”‚
â”‚ English, French, ... â”‚           â”‚   id, word_lb, audio_   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚   filename, category_id,â”‚
                                   â”‚   translations,         â”‚
         reference_audio/          â”‚   praat_features_json   â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ hond1.wavâ”‚â”€â”€precomputeâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ kaz1.wav â”‚   features    (stored as JSON in the
         â”‚ ...      â”‚               praat_features_json col)
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The import script (`scripts/import_csv.py`):
1. Reads each CSV row
2. Creates the category if it doesn't exist (auto-slugifies the name)
3. Inserts the word with all translations
4. Validates the matching audio file exists in `reference_audio/`

Then `scripts/precompute_features.py`:
1. Loads each reference WAV through Praat
2. Extracts pitch contour, formants (F1-F3), intensity, duration, jitter, shimmer
3. Stores the feature vectors as JSON in the `praat_features_json` column
4. These pre-computed features are loaded at scoring time â€” no reanalysis on every request

---

## Adding New Words & Categories

### Add a single new word

1. **Record the audio** â€” record a native speaker saying the word clearly. Save as WAV.

2. **Drop the WAV** into `backend/reference_audio/`:
   ```
   backend/reference_audio/yourword1.wav
   ```

3. **Add a row** to `backend/data/words.csv`:
   ```csv
   YOURWORD1,yourword1,YourCategory,Yourword,english,french,german
   ```
   - If `YourCategory` doesn't exist yet, it will be created automatically
   - The `Audio Reference` column (`yourword1`) must match the filename minus `.wav`

4. **Re-run the pipeline**:
   ```bash
   cd backend
   python -m scripts.pipeline
   ```
   This validates the CSV, standardizes the audio, imports into the DB, and extracts Praat features â€” all in one command.

5. **Restart the server** â€” the new word appears immediately.

### Add a whole new category

Just use a new category name in the `Word Category` column of the CSV. The system auto-creates categories during import. Add as many words as you want under that name.

For the category to show an emoji on the landing page, add it to the `CATEGORY_EMOJI` map in two files:
- `app.js` (line ~5) â€” landing page cards
- `topic.js` (line ~30) â€” practice page header

```js
const CATEGORY_EMOJI = {
  greetings: "ğŸ‘‹", animals: "ğŸ¾", house: "ğŸ ", outdoor: "ğŸŒ³",
  family: "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§", food: "ğŸ”", drinks: "ğŸ¥¤", colours: "ğŸ¨",
  yournewcategory: "ğŸ†•",  // â† add here
};
```

### Bulk data refresh

If you've changed many words or audio files at once:

```bash
cd backend

# Full pipeline: validate â†’ preprocess audio â†’ clean import â†’ extract features
python -m scripts.pipeline

# Or step by step:
python -m scripts.validate_data --csv data/words.csv --audio-dir reference_audio
python -m scripts.prepare_audio --audio-dir reference_audio --backup
python -m scripts.import_csv --csv data/words.csv --audio-dir reference_audio --clean
python -m scripts.precompute_features
```

| Script | What it does | When to run |
|--------|-------------|-------------|
| `validate_data.py` | Checks CSV integrity, verifies audio files exist, checks audio duration & silence | Before any import |
| `prepare_audio.py` | Converts all audio to mono 22050Hz -20dBFS WAV, trims silence | When adding raw recordings |
| `import_csv.py` | Reads CSV â†’ creates categories + words in SQLite | After CSV changes |
| `precompute_features.py` | Extracts Praat features for every reference WAV â†’ stores in DB | After audio changes |
| `pipeline.py` | Runs all four above in sequence | When in doubt, run this |

### Future extension ideas

| Feature | What to change |
|---------|---------------|
| **More languages** | Add columns to CSV (e.g. `Portuguese`), update `import_csv.py` INSERT, add `pt` to `/words` route lang query |
| **Sentence-level practice** | CSV already supports multi-word entries; the audio pipeline handles them naturally |
| **Difficulty tiers** | Add a `difficulty` column to CSV/DB, filter in the words API route |
| **User accounts / progress** | Add a `users` + `attempts` table to `database.py`, new routes in `routes/` |
| **Different scoring models** | Edit weights in `feature_comparator.py` or swap in a ML model |
| **Mobile app** | The API is framework-agnostic â€” any mobile client can POST to `/api/pronunciation/check` |

---

## Project Structure

```
speakingbuddy/
â”‚
â”‚  â”Œâ”€ FRONTEND (served as static files by FastAPI) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚                                                          â”‚
â”œâ”€â”€ index.html              â† Landing page (dynamic grid)    â”‚
â”œâ”€â”€ app.js                  â† Fetches categories, renders    â”‚
â”œâ”€â”€ topic.html              â† Practice page (single page     â”‚
â”œâ”€â”€ topic.js                â†   for all categories)          â”‚
â”œâ”€â”€ topic.css               â† Practice page styles           â”‚
â”œâ”€â”€ style.css               â† Global styles                  â”‚
â”œâ”€â”€ js/                                                       â”‚
â”‚   â”œâ”€â”€ config.js           â† API URL (auto-detects port)    â”‚
â”‚   â””â”€â”€ api.js              â† 4 fetch wrappers for the API   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”‚  â”Œâ”€ BACKEND â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€ backend/                                                  â”‚
    â”œâ”€â”€ requirements.txt    â† Python dependencies             â”‚
    â”œâ”€â”€ .env                â† Local config (CORS, port)       â”‚
    â”‚                                                          â”‚
    â”œâ”€â”€ data/               â† DATA LAYER                      â”‚
    â”‚   â”œâ”€â”€ words.csv       â†   Source of truth (38 words)    â”‚
    â”‚   â””â”€â”€ speakingbuddy.dbâ†   Generated SQLite DB           â”‚
    â”œâ”€â”€ reference_audio/    â†   38 native speaker WAVs        â”‚
    â”‚                                                          â”‚
    â”œâ”€â”€ app/                â† APPLICATION LAYER                â”‚
    â”‚   â”œâ”€â”€ main.py         â†   FastAPI entry + static mount  â”‚
    â”‚   â”œâ”€â”€ config.py       â†   Settings from .env            â”‚
    â”‚   â”œâ”€â”€ database.py     â†   SQLite schema + connection    â”‚
    â”‚   â”œâ”€â”€ models.py       â†   Pydantic schemas              â”‚
    â”‚   â”œâ”€â”€ routes/         â†   API ENDPOINTS                  â”‚
    â”‚   â”‚   â”œâ”€â”€ categories.py   â† GET /api/categories         â”‚
    â”‚   â”‚   â”œâ”€â”€ words.py        â† GET /api/categories/{}/wordsâ”‚
    â”‚   â”‚   â”œâ”€â”€ audio.py        â† GET /api/audio/{word_id}    â”‚
    â”‚   â”‚   â””â”€â”€ pronunciation.pyâ† POST /api/pronunciation/checkâ”‚
    â”‚   â””â”€â”€ services/       â†   PRONUNCIATION ENGINE           â”‚
    â”‚       â”œâ”€â”€ audio_processor.py   â† WebMâ†’WAV, normalize    â”‚
    â”‚       â”œâ”€â”€ praat_analyzer.py    â† Feature extraction      â”‚
    â”‚       â”œâ”€â”€ feature_comparator.pyâ† DTW + scoring           â”‚
    â”‚       â””â”€â”€ feedback_generator.pyâ† Human-readable tips     â”‚
    â”‚                                                          â”‚
    â””â”€â”€ scripts/            â† DATA PIPELINE                    â”‚
        â”œâ”€â”€ import_csv.py          â† CSV â†’ SQLite             â”‚
        â”œâ”€â”€ precompute_features.py â† WAV â†’ Praat JSON         â”‚
        â”œâ”€â”€ prepare_audio.py       â† Standardize audio        â”‚
        â”œâ”€â”€ validate_data.py       â† Pre-import checks        â”‚
        â””â”€â”€ pipeline.py            â† One-command chain        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key files to read first (in this order)

| # | File | What you'll learn |
|---|------|-------------------|
| 1 | `backend/app/main.py` | How the app boots: CORS, routers, static file mount |
| 2 | `backend/app/routes/pronunciation.py` | The core endpoint: upload â†’ preprocess â†’ analyze â†’ compare â†’ score â†’ respond |
| 3 | `backend/app/services/praat_analyzer.py` | What acoustic features Praat extracts and how |
| 4 | `backend/app/services/feature_comparator.py` | How user vs reference features are scored (DTW, Gaussian similarity, weights) |
| 5 | `topic.js` | Frontend: flashcard navigation, mic recording, evaluate flow |
| 6 | `js/api.js` | 4 fetch wrappers â€” the entire frontendâ†”backend contract |
| 7 | `backend/data/words.csv` | The raw data â€” understand what drives everything |

---

## How It All Connects (MVP Architecture)

### System diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        localhost:8000                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Static Files     â”‚     â”‚       FastAPI Backend          â”‚  â”‚
â”‚  â”‚  (index.html,      â”‚     â”‚                                â”‚  â”‚
â”‚  â”‚   topic.html,      â”‚     â”‚  /api/categories â”€â”€â”€â”€â”€â”€â”       â”‚  â”‚
â”‚  â”‚   app.js, etc.)    â”‚     â”‚  /api/.../words â”€â”€â”€â”€â”€â”€â”€â”¤       â”‚  â”‚
â”‚  â”‚                    â”‚     â”‚  /api/audio/{id} â”€â”€â”€â”€â”€â”€â”¤       â”‚  â”‚
â”‚  â”‚  Served at /       â”‚     â”‚  /api/pronunciation/ â”€â”€â”¤       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚                        â–¼       â”‚  â”‚
â”‚                              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚                              â”‚  â”‚     SQLite Database      â”‚ â”‚  â”‚
â”‚                              â”‚  â”‚  categories | words      â”‚ â”‚  â”‚
â”‚                              â”‚  â”‚  (praat_features_json)   â”‚ â”‚  â”‚
â”‚                              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚                              â”‚            â”‚                   â”‚  â”‚
â”‚                              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚                              â”‚  â”‚  Pronunciation Engine    â”‚ â”‚  â”‚
â”‚                              â”‚  â”‚  audio_processor â†’       â”‚ â”‚  â”‚
â”‚                              â”‚  â”‚  praat_analyzer â†’        â”‚ â”‚  â”‚
â”‚                              â”‚  â”‚  feature_comparator â†’    â”‚ â”‚  â”‚
â”‚                              â”‚  â”‚  feedback_generator      â”‚ â”‚  â”‚
â”‚                              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²                              â–²
         â”‚  Browser loads HTML/JS       â”‚  API calls (fetch)
         â”‚  from same origin            â”‚  from same origin
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The complete user flow (step by step)

| Step | Component | File | What happens |
|------|-----------|------|-------------|
| 1 | Browser | `index.html` + `app.js` | Page loads â†’ `GET /api/categories` â†’ renders 8 category cards with emoji + word count |
| 2 | Browser | `app.js` | User clicks a card â†’ navigates to `topic.html?category=animals&lang=en` |
| 3 | Browser | `topic.js` | Page loads â†’ `GET /api/categories/animals/words?lang=en` â†’ receives word list with IDs + translations |
| 4 | Browser | `topic.js` | Renders first flashcard: Luxembourgish word, translation, Listen/Record buttons |
| 5 | Browser | `topic.js` | User clicks **Listen** â†’ `GET /api/audio/1` â†’ backend streams `hond1.wav` â†’ `<audio>` plays it |
| 6 | Backend | `routes/audio.py` | `FileResponse` streams the WAV from `reference_audio/` directory |
| 7 | Browser | `topic.js` | User clicks **ğŸ™ï¸** â†’ `navigator.mediaDevices.getUserMedia()` â†’ `MediaRecorder` starts capturing |
| 8 | Browser | `topic.js` | Real-time mic level meter animates via `AudioContext` + `AnalyserNode` |
| 9 | Browser | `topic.js` | User clicks **ğŸ™ï¸** again â†’ recording stops â†’ WebM `Blob` stored in memory |
| 10 | Browser | `topic.js` | User clicks **Evaluate** â†’ `POST /api/pronunciation/check` with `FormData` (word_id + audio blob) |
| 11 | Backend | `routes/pronunciation.py` | Receives upload, validates word exists in DB, loads pre-computed reference features |
| 12 | Backend | `audio_processor.py` | Converts WebM â†’ WAV (mono, 22050Hz), normalizes to -20dBFS, trims silence, isolates first word |
| 13 | Backend | `praat_analyzer.py` | Runs Praat via parselmouth: extracts pitch contour, formants F1-F3, intensity envelope, duration, jitter, shimmer |
| 14 | Backend | `feature_comparator.py` | Compares user features vs reference features using DTW (time alignment) + Gaussian similarity â†’ weighted sub-scores â†’ overall score 0-100 |
| 15 | Backend | `feedback_generator.py` | Analyzes which sub-scores are low â†’ generates specific tips ("Your vowel quality differs â€” focus on mouth openness") |
| 16 | Backend | `routes/pronunciation.py` | Returns JSON: `{score, feedback, breakdown: {pitch, formants, intensity, duration, voice_quality}, improvements, suggestions}` |
| 17 | Browser | `topic.js` | Renders overall score with color (green â‰¥70, yellow â‰¥40, red <40), 5 animated breakdown bars, improvement tips |

### Scoring breakdown

| Feature | Weight | What Praat measures | What it tells the user |
|---------|--------|--------------------|-----------------------|
| Formants | 35% | F1, F2, F3 frequencies (vowel resonances) | "Your mouth shape/tongue position differs from native" |
| Pitch | 20% | Fundamental frequency (F0) contour over time | "Your intonation pattern doesn't match" |
| Intensity | 15% | Energy envelope over time | "Your volume/stress pattern is off" |
| Duration | 15% | Total speaking time vs reference | "You spoke too fast/slow" |
| Voice Quality | 15% | Jitter (pitch instability) + shimmer (amplitude instability) | "Your voice was shaky/unstable" |

The comparison uses:
- **DTW (Dynamic Time Warping)** for pitch, formants, and intensity â€” aligns time-series of different lengths before comparing
- **Gaussian similarity** for scalar values (duration, jitter, shimmer) â€” smooth falloff rather than hard thresholds

### API contract

| Method | Endpoint | Request | Response |
|--------|----------|---------|----------|
| GET | `/api/categories` | â€” | `[{id, name, display_name, image_url, word_count}]` |
| GET | `/api/categories/{name}/words?lang=en` | `lang` = `en`/`fr`/`de` | `[{id, word_lb, translation, gender, audio_url}]` |
| GET | `/api/audio/{word_id}` | â€” | Binary WAV stream |
| POST | `/api/pronunciation/check` | `FormData: word_id (int) + audio (file)` | `{score, feedback, breakdown: {pitch, formants, intensity, duration, voice_quality}, improvements[], suggestions[]}` |
| GET | `/api/health` | â€” | `{"status": "ok"}` |

### Tech stack

| Layer | Technology | Why |
|-------|-----------|-----|
| Frontend | Vanilla HTML/CSS/JS | No build step, instant reload, minimal complexity |
| Backend | Python 3.10 + FastAPI + uvicorn | Async, fast, auto-docs at `/docs`, great for prototyping |
| Database | SQLite via aiosqlite | Zero config, single file, good enough for MVP |
| Audio analysis | Praat (parselmouth) + pydub + librosa + scipy | Gold standard in phonetics research, proven algorithms |
| Audio pipeline | ffmpeg (via pydub) | Universal format conversion, handles WebM from browsers |

---

## Project Outline Mapping

This section shows how each part of the codebase maps back to the original project plan.

### Phase A â€” Backend Scaffolding
> *"Set up project structure, database, configuration"*

| Deliverable | File(s) | Status |
|------------|---------|--------|
| FastAPI project structure | `backend/app/main.py`, `config.py` | âœ… Done |
| SQLite schema (categories + words) | `backend/app/database.py` | âœ… Done |
| Environment config (.env) | `backend/.env`, `config.py` | âœ… Done |
| CSV import script | `backend/scripts/import_csv.py` | âœ… Done |
| 38 words Ã— 8 categories loaded | `backend/data/words.csv` â†’ DB | âœ… Done |

### Phase B â€” Core API Endpoints
> *"CRUD endpoints for categories, words, audio streaming"*

| Deliverable | File(s) | Status |
|------------|---------|--------|
| `GET /api/categories` with word count | `routes/categories.py` | âœ… Done |
| `GET /api/categories/{name}/words` with lang filter | `routes/words.py` | âœ… Done |
| `GET /api/audio/{word_id}` WAV streaming | `routes/audio.py` | âœ… Done |
| Pydantic request/response models | `models.py` | âœ… Done |

### Phase C â€” Praat Pronunciation Engine
> *"Port the Praat analysis pipeline from prototype, wire to API"*

| Deliverable | File(s) | Status |
|------------|---------|--------|
| Audio preprocessing (WebMâ†’WAV, normalize, trim) | `services/audio_processor.py` | âœ… Done |
| Praat feature extraction (pitch, formants, intensity, duration, voice quality) | `services/praat_analyzer.py` | âœ… Done |
| DTW + Gaussian weighted comparison | `services/feature_comparator.py` | âœ… Done |
| Human-readable feedback generation | `services/feedback_generator.py` | âœ… Done |
| `POST /api/pronunciation/check` endpoint | `routes/pronunciation.py` | âœ… Done |
| Pre-computed reference features in DB | `scripts/precompute_features.py` | âœ… Done |
| Tested: 99.7 self-score, 51.3 cross-word score | â€” | âœ… Verified |

### Phase D â€” Frontend Refactor
> *"Replace 8 static topic folders with single dynamic page driven by API"*

| Deliverable | File(s) | Status |
|------------|---------|--------|
| Dynamic landing page (categories from API) | `index.html`, `app.js` | âœ… Done |
| Single topic page for all categories | `topic.html`, `topic.js`, `topic.css` | âœ… Done |
| Shared API client | `js/config.js`, `js/api.js` | âœ… Done |
| Old 8 topic folders deleted | `animals/`, `colors/`, etc. | âœ… Removed |

### Phase E â€” Data Pipeline
> *"Automated audio preparation, validation, and import"*

| Deliverable | File(s) | Status |
|------------|---------|--------|
| Audio standardization (22050Hz, mono, -20dBFS) | `scripts/prepare_audio.py` | âœ… Done |
| Pre-import data validation | `scripts/validate_data.py` | âœ… Done |
| One-command pipeline | `scripts/pipeline.py` | âœ… Done |

### Phase F â€” Deployment
> *"Host for demo / production"*

| Deliverable | Status |
|------------|--------|
| FastAPI serves frontend directly (no separate web server) | âœ… Done |
| Cloud deployment | â¸ï¸ Deferred â€” local demo for MVP |

---

## MVP Presentation Talking Points

### 1. The Problem
Learning Luxembourgish pronunciation is hard. Existing tools only mark answers "right" or "wrong" â€” they can't tell you *what's wrong* with how you said it.

### 2. Our Solution
SpeakingBuddy gives instant, detailed pronunciation feedback. Not just pass/fail â€” it scores you across 5 acoustic dimensions and tells you specifically what to improve.

### 3. Live Demo Flow (â‰ˆ 60 seconds)

1. **Open the app** â†’ landing page shows 8 word categories
2. **Pick "Animals"** â†’ flashcard shows "Hond" (dog) with English translation
3. **Click Listen** â†’ hear the native Luxembourgish pronunciation
4. **Click the microphone** â†’ record yourself saying "Hond" â†’ click again to stop
5. **Click Evaluate** â†’ within 2 seconds:
   - Overall score: **78/100**
   - Breakdown bars: Pitch 85, Formants 62, Intensity 81, Duration 90, Voice Quality 94
   - Tip: *"Your vowel quality differs â€” try opening your mouth wider"*
6. **Click Next** â†’ practice the next word

### 4. How It Works Under the Hood

> "We're not just comparing waveforms. We use **Praat** â€” the same acoustic analysis tool used in university phonetics research â€” to extract 5 measurable features from your voice and compare them to a native speaker recording."

- **Formants** = vowel quality (is your mouth the right shape?)
- **Pitch** = intonation (does your melody match?)
- **Duration** = timing (too fast? too slow?)
- **Voice quality** = stability (is your voice steady?)
- We use **DTW (Dynamic Time Warping)** to handle natural speed differences

### 5. Technical Simplicity

- **No cloud services** needed â€” runs locally with one command
- **No ML training data** needed â€” scoring is based on acoustic physics
- **38 words ready** across 8 categories, trivially extensible via CSV
- **Any browser** with a microphone works (Chrome, Firefox, Edge)
- **One file to add words** â€” edit the CSV, drop a WAV, run the pipeline

### 6. What's Next (Roadmap)

| Priority | Feature | Effort |
|----------|---------|--------|
| High | More words & categories | Low (CSV + audio) |
| High | Progress tracking (per user) | Medium (new DB tables + routes) |
| Medium | Difficulty levels (word â†’ phrase â†’ sentence) | Low (CSV filtering) |
| Medium | Mobile-optimized UI | Medium (CSS responsive) |
| Low | Cloud deployment (Azure/Railway) | Medium (Dockerfile + config) |
| Low | ML-based scoring model | High (training data collection) |

---

## Commit History

```
deb09b3 docs: add README with setup guide, architecture, and MVP outline
6dcd274 fix: serve frontend from FastAPI, fix evaluate button reload
0f19474 chore: remove old static topic folders
eba41f4 refactor: dynamic frontend with API-driven categories and topics
a8657f3 feat: port Praat pronunciation engine from prototype
2209d64 feat: add data pipeline and import scripts
7a12e07 feat: add backend scaffolding with FastAPI and SQLite
```
